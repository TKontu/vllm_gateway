networks:
  vllm_network:
    driver: bridge

services:
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    image: my-vlmm-gateway:latest
    container_name: vllm_gateway
    ports:
      - "9003:9000"
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
      DOCKER_NETWORK_NAME: vllm_network
      GATEWAY_CONTAINER_NAME: "vllm_gateway"
      VLLM_HOST: vllm_server
      VLLM_INACTIVITY_TIMEOUT: "1800"
      ALLOWED_MODELS_JSON: '{"gemma3-4B":"google/gemma-3-4b-it","gemma3-12B":"google/gemma-3-12b-it","qwen2.5":"Qwen/Qwen2.5-Coder-7B-Instruct", "gpt-oss":"openai/gpt-oss-20b", "deepseek-r1-14B":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "bge-large":"BAAI/bge-large-en-v1.5"}'
      VLLM_GPU_MEMORY_UTILIZATION: ${VLLM_GPU_MEMORY_UTILIZATION}
      VLLM_MAX_NUM_SEQS: ${VLLM_MAX_NUM_SEQS:-16}
      LOG_LEVEL: "DEBUG"
      VLLM_TENSOR_PARALLEL_SIZE: ${VLLM_TENSOR_PARALLEL_SIZE:-1}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /root/.cache/huggingface:/root/.cache/huggingface
      - ./memory_footprints.json:/app/memory_footprints.json

    networks:
      - vllm_network

    restart: unless-stopped
