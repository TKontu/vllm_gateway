networks:
  vllm_network:
    driver: bridge

services:
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    image: my-vlmm-gateway:latest
    container_name: vllm_gateway
    ports:
      - "9003:9000"
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
      DOCKER_NETWORK_NAME: vllm_network
      GATEWAY_CONTAINER_NAME: "vllm_gateway" # Add this line
      VLLM_HOST: vllm_server
      VLLM_INACTIVITY_TIMEOUT: "1800" # 1800 seconds = 30 minutes
      ALLOWED_MODELS_JSON: '{"gemma3-4B":"google/gemma-3-4b-it","gemma3-12B":"google/gemma-3-12b-it","qwen2.5":"Qwen/Qwen2.5-Coder-7B-Instruct", "gpt-oss":"openai/gpt-oss-20b", "deepseek-r1-14B":"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "bge-large":"BAAI/bge-large-en-v1.5", "bge-reranker-v2-m3":"BAAI/bge-reranker-v2-m3"}'
      VLLM_GPU_MEMORY_UTILIZATION: ${VLLM_GPU_MEMORY_UTILIZATION} # Or any value between 0.1 and 1.0
      LOG_LEVEL: "DEBUG"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /root/.cache/huggingface:/root/.cache/huggingface
      - ./memory_footprints.json:/app/memory_footprints.json

    networks:
      - vllm_network

    restart: unless-stoppedBAAI/bge-reranker-v2-m3
